{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e58ad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Tratamento dos dados e Estatística Descritiva\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Processamento de Texto\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "import nltk.corpus   \n",
    "from unidecode                        import unidecode\n",
    "from nltk.tokenize                    import word_tokenize\n",
    "from nltk                             import SnowballStemmer\n",
    "from sklearn.feature_extraction.text  import TfidfVectorizer\n",
    "from sklearn.preprocessing            import normalize\n",
    "\n",
    "# Nuvem de palavras\n",
    "from wordcloud                        import WordCloud\n",
    "\n",
    "# K-Means\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics                  import silhouette_samples, silhouette_score, v_measure_score\n",
    "from sklearn import cluster\n",
    "\n",
    "# SVD\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Agglomerative Clustering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49f5f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pasta de trabalho\n",
    "dir = 'C:\\\\Users\\\\amand\\\\OneDrive\\\\Documentos\\\\TCC PUC\\\\NewsFake'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b016df",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(dir + \"/*.csv\")\n",
    "\n",
    "data_frame = pd.DataFrame()\n",
    "content = []\n",
    "\n",
    "for filename in files:\n",
    "    \n",
    "    # lendo conteúdo de um arquivo CSV\n",
    "    df = pd.read_csv(filename, index_col=None)\n",
    "    content.append(df)\n",
    "  \n",
    "# convertendo conteúdo para DataFrame\n",
    "frame = pd.concat(content)\n",
    "print(frame)\n",
    "\n",
    "print('Datasets: \\n   {}\\n'.format(files))\n",
    "print('Quantidade de Datasets:{}'.format(len(files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2ecff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = pd.DataFrame()\n",
    "\n",
    "frame[['https','vazio','fonte','resto']] = frame['news_url'].str.split('/',n=3,expand=True)\n",
    "display(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90159494",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = frame[['title','type','fonte']].copy()\n",
    "\n",
    "display(dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da840fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pasta de trabalho\n",
    "dir2 = 'C:\\\\Users\\\\amand\\\\OneDrive\\\\Documentos\\\\TCC PUC\\\\ClaimFake'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad7efff",
   "metadata": {},
   "outputs": [],
   "source": [
    "files2 = glob.glob(dir2 + \"/*.csv\")\n",
    "\n",
    "data_frame2 = pd.DataFrame()\n",
    "content2 = []\n",
    "\n",
    "for filename in files2:\n",
    "    \n",
    "    # reading content of csv file\n",
    "    # content.append(filename)\n",
    "    df = pd.read_csv(filename, index_col=None)\n",
    "    content2.append(df)\n",
    "  \n",
    "# convertendo conteúdo para data frame\n",
    "frame2 = pd.concat(content2)\n",
    "print(frame2)\n",
    "\n",
    "print('Datasets: \\n   {}\\n'.format(files2))\n",
    "print('Quantidade de Datasets:{}'.format(len(files2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf0fd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = pd.DataFrame()\n",
    "\n",
    "dataset2 = frame2[['title']].copy()\n",
    "dataset2.loc[:, 'type'] = 'article'\n",
    "dataset2.loc[:, 'fonte'] = 'www.medicalnewstoday.com'\n",
    "\n",
    "display(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4815b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pasta de trabalho\n",
    "dir3 = 'C:\\\\Users\\\\amand\\\\OneDrive\\\\Documentos\\\\TCC PUC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248420e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "files3 = glob.glob(dir3 + \"/*.csv\")\n",
    "\n",
    "data_frame3 = pd.DataFrame()\n",
    "content3 = []\n",
    "\n",
    "for filename in files3:\n",
    "    \n",
    "    # reading content of csv file\n",
    "    # content.append(filename)\n",
    "    df = pd.read_csv(filename, index_col=None)\n",
    "    content3.append(df)\n",
    "  \n",
    "# convertendo conteúdo em um dataframe\n",
    "frame3 = pd.concat(content3)\n",
    "print(frame3)\n",
    "\n",
    "print('Datasets: \\n   {}\\n'.format(files3))\n",
    "print('Quantidade de Datasets:{}'.format(len(files3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bc3ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {'id': 'id',\n",
    "        'tweet': 'title',\n",
    "        'label': 'label'}\n",
    "\n",
    "frame3.rename(columns=dict,\n",
    "          inplace=True)\n",
    "\n",
    "dataset3 = pd.DataFrame()\n",
    "\n",
    "dataset3 = frame3[['title']].copy().loc[frame3['label'] == 'fake']\n",
    "dataset3.loc[:, 'type'] = 'tweet'\n",
    "dataset3.loc[:, 'fonte'] = 'twitter.com'\n",
    "\n",
    "display(dataset3)\n",
    "\n",
    "#conferindo se pegou todas as linhas \"fake\"\n",
    "\n",
    "fake_frame = frame3.loc[frame3['label'] == 'fake']\n",
    "\n",
    "print ('Quantidade de linhas com Fake News:{}'.format(len(fake_frame)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33195bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final = pd.DataFrame()\n",
    "base_final = pd.concat([dataset1, dataset2, dataset3])\n",
    "\n",
    "display(base_final)\n",
    "\n",
    "base_final.loc[base_final.fonte == 'twitter.com','type'] = 'tweet'\n",
    "\n",
    "display(base_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c2df56",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final.loc[:, 'fonte'] = base_final['fonte'].apply(lambda x: 'Twitter' if x == 'twitter.com'\n",
    "                                                       else 'Facebook' if x == 'www.facebook.com'\n",
    "                                                       else 'Instagram' if x == 'www.instagram.com'\n",
    "                                                       else 'Youtube' if x == 'www.youtube.com'\n",
    "                                                       else 'Website')\n",
    "\n",
    "display(base_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90325849",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e213e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removendo valores duplicados\n",
    "base_final.drop_duplicates(inplace=True)\n",
    "\n",
    "base_final.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c092b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final.loc[:, 'Tamanho_Texto'] = base_final['title'].apply(lambda x: len(x))\n",
    "\n",
    "display(base_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52c597e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separando hashtags\n",
    "hash_frame = base_final['title'].tolist()\n",
    "list_hashtags=[]\n",
    "for text in hash_frame:\n",
    "    for i in text.split():\n",
    "        if i[0]=='#':\n",
    "            list_hashtags.append(i)\n",
    "            ''.join(list_hashtags)\n",
    "            \n",
    "hashtags = ','.join(list_hashtags)\n",
    "\n",
    "df_hash = pd.DataFrame(list_hashtags, columns=['hashtag'])\n",
    "display(df_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de25294",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Countplot do comparativo da quantidade total de tipo de \"news\"\n",
    "fig = plt.subplots(figsize =(8,5))\n",
    "sns.countplot(base_final['type'],palette='YlGnBu')\n",
    "plt.title('Quantidade de tipos de posts', fontweight='bold', fontsize=16)\n",
    "plt.xlabel('Tipo',fontweight='bold',fontsize=12)\n",
    "plt.ylabel('Quantidade', fontsize=12, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cbbca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Countplot do comparativo da quantidade total de tipo de fonte\n",
    "fig = plt.subplots(figsize =(8,5))\n",
    "sns.countplot(base_final['fonte'],palette='YlGnBu')\n",
    "plt.title('Quantidade de fontes', fontweight='bold', fontsize=16)\n",
    "plt.xlabel('Fonte',fontweight='bold',fontsize=12)\n",
    "plt.ylabel('Quantidade', fontsize=12, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077bb3b0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plotting the pie chart for above dataframe\n",
    "base_final.groupby(['type']).count().plot(\n",
    "    kind='pie', y='title', autopct='%1.0f%%',\n",
    "    colors = ['yellow','steelblue','orange'],\n",
    "    title='Quantidade de textos por tipo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f63d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the pie chart for above dataframe\n",
    "media_frame = base_final.loc[base_final['type'] != 'tweet']\n",
    "media_frame.groupby(['fonte']).count().plot(\n",
    "    kind='pie', y='title', autopct='%1.0f%%',\n",
    "    title='Proporção de outras redes sociais')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74045b43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#gráfico de distribuição tamanho dos titulos de noticias/posts/tweets\n",
    "fig = plt.subplots(figsize=(7,3))\n",
    "g = sns.distplot(base_final['Tamanho_Texto'])\n",
    "plt.title('Distribuição de tamanhos de posts', fontweight='bold', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d500b9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gráfico de distribuição tamanho dos titulos de noticias/posts/tweets\n",
    "fig = plt.subplots(figsize=(7,3))\n",
    "g = sns.distplot(base_final['Tamanho_Texto'])\n",
    "g.set(xlim=(0,750))\n",
    "plt.title('Distribuição de tamanhos de posts', fontweight='bold', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07609cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplot tamanho dos titulos de noticias/posts/tweets\n",
    "fig,ax = plt.subplots(figsize=(8,5))\n",
    "sns.boxplot(y=base_final['Tamanho_Texto'])\n",
    "plt.title('Boxplot de tamanhos de posts', fontweight='bold', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885fd5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final['Tamanho_Texto'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8fab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final[base_final['Tamanho_Texto'] == 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fff932c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 4000\n",
    "base_final[base_final['Tamanho_Texto'] == 8846]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690054bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declarando funções para Stop Words e Stemming\n",
    "\n",
    "# retira Stop Words\n",
    "def tiraStopWords(listOfTokens, listOfWords):\n",
    "    return [token for token in listOfTokens if token not in listOfWords]\n",
    "\n",
    "# aplica Stemming\n",
    "def aplicaStemming(listOfTokens, stemmer):\n",
    "    return [stemmer.stem(token) for token in listOfTokens]\n",
    "\n",
    "# retira palavras com menos de 2 caracteres e com mais de 21 caracteres\n",
    "def tiraMinMaxCaracteres(listOfTokens):\n",
    "    twoLetterWord = []\n",
    "    for token in listOfTokens:\n",
    "        if len(token) <= 2 or len(token) >= 21:\n",
    "            twoLetterWord.append(token)\n",
    "    return twoLetterWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df279a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = base_final['title'].tolist()\n",
    "\n",
    "def processaTexto(texto, lingua):   \n",
    "    stopwords = nltk.corpus.stopwords.words(lingua)\n",
    "    param_stemmer = SnowballStemmer(lingua)\n",
    "    \n",
    "    for title in texto:\n",
    "        ind = texto.index(title)\n",
    "        texto[ind] = texto[ind].replace('@', '') #removendo @\n",
    "        texto[ind] = texto[ind].replace(',', '') #removendo ,\n",
    "        texto[ind] = texto[ind].rstrip('\\n') #removendo espaço em branco\n",
    "        texto[ind] = texto[ind].casefold() #tornando todas as letras minúsculas\n",
    "\n",
    "        texto[ind] = re.sub('\\W_',' ', texto[ind]) #tirando caracteres especiais\n",
    "        texto[ind] = re.sub(\"\\S*\\d\\S*\",\" \", texto[ind]) #tira números e palavras concatenados com nº,ex: h4ck3r\n",
    "        texto[ind] = re.sub(\"\\S*@\\S*\\s?\",\" \", texto[ind]) #tira palavras com @\n",
    "        texto[ind] = re.sub(r'http\\S+', '', texto[ind]) #tira URL com http\n",
    "        texto[ind] = re.sub(r'www\\S+', '', texto[ind]) #tira URL com www\n",
    "        \n",
    "        listOfTokens = word_tokenize(texto[ind])\n",
    "        minMaxWord = tiraMinMaxCaracteres(listOfTokens)\n",
    "        \n",
    "        listOfTokens = tiraStopWords(listOfTokens, stopwords)\n",
    "        listOfTokens = tiraStopWords(listOfTokens, minMaxWord)\n",
    "        listOfTokens = aplicaStemming(listOfTokens, param_stemmer)\n",
    "        \n",
    "        texto[ind]   = \" \".join(listOfTokens)\n",
    "        texto[ind] = unidecode(texto[ind])\n",
    "    \n",
    "    return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a6e8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lingua = 'english'\n",
    "texto = processaTexto(texto, lingua)\n",
    "\n",
    "display(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bffbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(texto)\n",
    "tf_idf = pd.DataFrame(data = X.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "final_df = tf_idf\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad4e78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conteudo = ' '.join(final_df)\n",
    "wordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(conteudo)\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d487a638",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(hashtags)\n",
    "plt.figure(figsize=(12,9))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fceb14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acha um número ótimo de componentes a ser utilizado para o Truncated SVD\n",
    "n_comp = [4,10,15,20,50,100,150,200,500,700,800,900,1000,1500,2000,2500,3000,3500] \n",
    "explained = [] # variancia explicada para cada número de componente aplicado no Truncated SVD\n",
    "for x in n_comp:\n",
    "    svd = TruncatedSVD(n_components=x)\n",
    "    svd.fit(final_df)\n",
    "    explained.append(svd.explained_variance_ratio_.sum())\n",
    "    print(\"Number of components = %r and explained variance = %r\"%(x,svd.explained_variance_ratio_.sum()))\n",
    "plt.plot(n_comp, explained)\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel(\"Explained Variance\")\n",
    "plt.title(\"Plot of Number of components v/s explained variance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe84079",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=1500)\n",
    "final_df_svd = svd.fit_transform(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b962f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239bd3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numero_k(mink, maxk, X):\n",
    "  # Descobrindo qual o melhor valor de k\n",
    "  wcss = []\n",
    "  for i in range(mink,maxk):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', n_init=10, max_iter=200, random_state=0)\n",
    "    kmeans.fit(X)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "  # Plot do gráfico do cotovelo para visualizar o melhor valor de k\n",
    "  plt.figure(figsize=(10,5))\n",
    "  plt.plot(range(mink,maxk), wcss, 'bx-')\n",
    "  plt.xlabel('Valor de k')\n",
    "  plt.ylabel('Inertia')\n",
    "  plt.title('Método do Cotovelo exibindo número ótimo de k')\n",
    "  plt.show()\n",
    "\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87aebb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "numero_k(1, 20, final_df_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bb121b",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "\n",
    "for n_clusters in range(2 , k):\n",
    "    clusterer = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    cluster_labels = clusterer.fit_predict(final_df_svd)\n",
    "    silhouette_avg = silhouette_score(final_df_svd, cluster_labels)\n",
    "    print(\"Para n_clusters =\", n_clusters,\n",
    "          \"O score_silhouette médio é :\", silhouette_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dc38cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 11\n",
    "km = KMeans(algorithm='auto',\n",
    "            copy_x=True,\n",
    "            init='k-means++',\n",
    "            max_iter=300,\n",
    "            n_clusters=k,\n",
    "            n_init=10,\n",
    "            n_jobs=1,\n",
    "            precompute_distances='auto',\n",
    "            random_state=0,\n",
    "            tol=0.0001,\n",
    "            verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e4cf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "km.fit(final_df_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672da226",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = km.labels_\n",
    "k_centers = km.cluster_centers_ \n",
    "original_space_centroids = svd.inverse_transform(k_centers)\n",
    "order_centroids = original_space_centroids.argsort()[:, ::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf01bd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svd_cluster_topics = {}\n",
    "for c in range(k):\n",
    "    topic = ','.join([centroids.columns[i] for i in [ix for ix in order_centroids[c, :10]]])\n",
    "    svd_cluster_topics[c] = topic\n",
    "    print (\"Cluster %i: \" % c + topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a9ca81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inserindo a classificação de cluster para cada título\n",
    "labels = km.labels_ \n",
    "base_final[\"Cluster_Kmeans_SVD\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebb945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusters = base_final[\"Cluster_Kmeans_SVD\"].value_counts()\n",
    "print(df_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3341a5b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 193\n",
    "base_final.groupby('Cluster_Kmeans_SVD').head(1).sort_values(by='Cluster_Kmeans_SVD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c0b439",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,9))\n",
    "dendrograma = dendrogram(linkage(final_df_svd, method = 'ward'))\n",
    "plt.title('Dendrograma')\n",
    "plt.xlabel('Palavras')\n",
    "plt.ylabel('Distância Euclidiana')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a08459",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc = AgglomerativeClustering(n_clusters = 5, affinity = 'euclidean', linkage = 'ward')\n",
    "previsoes = hc.fit_predict(final_df_svd)\n",
    "labels = hc.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd6505d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_features_cluster(tf_idf_array, prediction, n_feats):\n",
    "    labels = np.unique(prediction)\n",
    "    dfs = []\n",
    "    for label in labels:\n",
    "        id_temp = np.where(prediction==label) # indices para cada cluster\n",
    "        x_means = np.mean(tf_idf_array[id_temp], axis = 0) # retorna score médio TF-IDF para cada palavra gerada no cluster\n",
    "        sorted_means = np.argsort(x_means)[::-1][:n_feats] # indices com os top n_feats scores\n",
    "        features = vectorizer.get_feature_names()\n",
    "        best_features = [(features[i], x_means[i]) for i in sorted_means]\n",
    "        df = pd.DataFrame(best_features, columns = ['features', 'score'])\n",
    "        dfs.append(df)\n",
    "    return dfs\n",
    "\n",
    "def plotWords(dfs, n_feats):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    for i in range(0, len(dfs)):\n",
    "        plt.title((\"Most Common Words in Cluster {}\".format(i)), fontsize=10, fontweight='bold')\n",
    "        sns.barplot(x = 'score' , y = 'features', orient = 'h' , data = dfs[i][:n_feats])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e082970b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_array = final_df.to_numpy()\n",
    "n_feats = 20\n",
    "dfs = get_top_features_cluster(final_df_array, previsoes, n_feats)\n",
    "plotWords(dfs, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb16f421",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final[\"Cluster_Agglomerative\"] = previsoes\n",
    "\n",
    "df_clusters2 = base_final[\"Cluster_Agglomerative\"].value_counts()\n",
    "print(df_clusters2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2618c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 193\n",
    "base_final.groupby('Cluster_Agglomerative').head(3).sort_values(by='Cluster_Agglomerative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1276a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.subplots(figsize =(8,5))\n",
    "sns.countplot(base_final['Cluster_Kmeans_SVD'],palette='YlGnBu')\n",
    "plt.title('Quantidade de texto por Cluster', fontweight='bold', fontsize=16)\n",
    "plt.xlabel('Cluster',fontweight='bold',fontsize=12)\n",
    "plt.ylabel('Quantidade', fontsize=12, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de50984b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.subplots(figsize =(8,5))\n",
    "sns.countplot(base_final['Cluster_Agglomerative'],palette='YlGnBu')\n",
    "plt.title('Quantidade de texto por Cluster', fontweight='bold', fontsize=16)\n",
    "plt.xlabel('Cluster',fontweight='bold',fontsize=12)\n",
    "plt.ylabel('Quantidade', fontsize=12, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa996b81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
